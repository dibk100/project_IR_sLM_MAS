{
  "task_id": "scikit-learn__scikit-learn-13496",
  "trial_id": 0,
  "context_used": true,
  "context_num_files": 80,
  "repo_context_preview": "Existing files (choose from these):\nsetup.py\nconftest.py\ndoc/conf.py\ndoc/conftest.py\nsklearn/base.py\nsklearn/dummy.py\nsklearn/setup.py\nsklearn/impute.py\nsklearn/_config.py\nsklearn/__init__.py\nsklearn/isotonic.py\nsklearn/pipeline.py\nsklearn/svm/base.py\nsklearn/svm/setup.py\nsklearn/tree/tree.py\nsklearn/exceptions.py\nsklearn/multiclass.py\nsklearn/svm/bounds.py\nsklearn/tree/setup.py\nsklearn/calibration.py\n... (+60 more)",
  "issue_text": null,
  "test_command": "",
  "diff": "diff --git a/sklearn/ensemble/base.py b/sklearn/ensemble/base.py\nindex 9b8c2d3..e4f5a6b 100644\n--- a/sklearn/ensemble/base.py\n+++ b/sklearn/ensemble/base.py\n@@ -100,6 +100,7 @@ class BaseBagging(MetaEstimatorMixin, ClassifierMixin, RegressorMixin,\n     n_estimators = None\n     max_samples = 1.0\n     max_features = 1.0\n+    warm_start = False\n \n     def __init__(self, base_estimator=None, n_estimators=100, max_samples=1.0,\n                  max_features=1.0, bootstrap=True, bootstrap_features=False,\ndiff --git a/sklearn/ensemble/iforest.py b/sklearn/ensemble/iforest.py\nindex 1a2b3c4..5d6e7f8 100644\n--- a/sklearn/ensemble/iforest.py\n+++ b/sklearn/ensemble/iforest.py\n@@ -10,6 +10,7 @@\n from ..base import BaseEnsemble, OutlierMixin\n from ..tree._tree import DTYPE, DOUBLE\n from ..utils.validation import check_X_y, check_array\n+from ..utils.validation import check_is_fitted\n from ..utils.extmath import weighted_mode\n from ..utils.sparsefuncs_fast import csr_mean_variance_axis0\n from ..utils.sparsefuncs import count_nonzero\n@@ -100,6 +101,7 @@ class IsolationForest(BaseEnsemble, OutlierMixin):\n     n_estimators = None\n     contamination = 'auto'\n     max_samples = 'auto'\n+    warm_start = False\n \n     def __init__(self, n_estimators=100, max_samples='auto', contamination='auto',\n                  max_features=1., bootstrap=False, n_jobs=None,\n@@ -110,6 +112,7 @@ class IsolationForest(BaseEnsemble, OutlierMixin):\n         self.n_estimators = n_estimators\n         self.max_samples = max_samples\n         self.contamination = contamination\n+        self.warm_start = warm_start\n         self.max_features = max_features\n         self.bootstrap = bootstrap\n         self.n_jobs = n_jobs\n@@ -120,6 +123,7 @@ class IsolationForest(BaseEnsemble, OutlierMixin):\n \n     def _fit(self, X, y=None):\n         # Check data\n+        check_is_fitted(self)\n         X = check_array(X, accept_sparse=\"csr\", dtype=DTYPE)\n         if isinstance(self.max_samples, str) and self.max_samples == 'auto':\n             self.max_samples = min(256, X.shape[0])\n@@ -130,6 +134,7 @@ class IsolationForest(BaseEnsemble, OutlierMixin):\n                 raise ValueError(\"max_samples must be in range (0, n_samples], \"\n                                  \" got %r\" % self.max_samples)\n \n+        if self.warm_start and hasattr(self, 'estimators_'):\n+            n_estimators_to_add = self.n_estimators - len(self.estimators_)\n+            self.n_estimators = len(self.estimators_)\n+            self._fit_stage(X, n_estimators_to_add)\n+        else:\n             self.estimators_ = []\n             self.estimators_features_ = []\n             self.estimators_samples_ = []\n@@ -140,6 +147,7 @@ class IsolationForest(BaseEnsemble, OutlierMixin):\n             self.estimators_n_node_samples_ = np.zeros((self.n_estimators,), dtype=np.int32)\n             self.estimators_max_depth_ = np.zeros((self.n_estimators,), dtype=np.int32)\n \n+            self._fit_stage(X, self.n_estimators)\n+\n         return self\n \n     def _fit_stage(self, X, n_estimators):\ndiff --git a/sklearn/ensemble/tests/test_iforest.py b/sklearn/ensemble/tests/test_iforest.py\nindex 5a6b7c8..9d0e1f2 100644\n--- a/sklearn/ensemble/tests/test_iforest.py\n+++ b/sklearn/ensemble/tests/test_iforest.py\n@@ -10,6 +10,7 @@\n from sklearn.datasets import make_classification\n from sklearn.metrics import roc_auc_score\n from sklearn.utils.testing import assert_almost_equal, assert_raises, assert_true\n+from sklearn.utils.testing import assert_array_equal\n from sklearn.utils.validation import NotFittedError\n \n \n@@ -100,6 +101,14 @@ def test_iforest():\n     assert_almost_equal(auc, 0.9, decimal=2)\n \n \n+def test_warm_start():\n+    X, y = make_classification(n_samples=100, n_features=20, random_state=42)\n+    clf = IsolationForest(warm_start=True, n_estimators=50)\n+    clf.fit(X)\n+    clf.set_params(n_estimators=100)\n+    clf.fit(X)\n+    assert_array_equal(len(clf.estimators_), 100)\n+\n \n if __name__ == '__main__':\n     import nose",
  "stdout": "",
  "stderr": "",
  "repo_commit": null,
  "docker_image": null,
  "model_config": null,
  "full_result": {
    "task_id": "scikit-learn__scikit-learn-13496",
    "trial_id": 0,
    "model": "Qwen/Qwen2.5-Coder-7B-Instruct",
    "prompt_hash": "6f0b73256c1d49e5e01b29127db1bd2a4332f4da700c0ffecaecd78434a64219",
    "diff": "diff --git a/sklearn/ensemble/base.py b/sklearn/ensemble/base.py\nindex 9b8c2d3..e4f5a6b 100644\n--- a/sklearn/ensemble/base.py\n+++ b/sklearn/ensemble/base.py\n@@ -100,6 +100,7 @@ class BaseBagging(MetaEstimatorMixin, ClassifierMixin, RegressorMixin,\n     n_estimators = None\n     max_samples = 1.0\n     max_features = 1.0\n+    warm_start = False\n \n     def __init__(self, base_estimator=None, n_estimators=100, max_samples=1.0,\n                  max_features=1.0, bootstrap=True, bootstrap_features=False,\ndiff --git a/sklearn/ensemble/iforest.py b/sklearn/ensemble/iforest.py\nindex 1a2b3c4..5d6e7f8 100644\n--- a/sklearn/ensemble/iforest.py\n+++ b/sklearn/ensemble/iforest.py\n@@ -10,6 +10,7 @@\n from ..base import BaseEnsemble, OutlierMixin\n from ..tree._tree import DTYPE, DOUBLE\n from ..utils.validation import check_X_y, check_array\n+from ..utils.validation import check_is_fitted\n from ..utils.extmath import weighted_mode\n from ..utils.sparsefuncs_fast import csr_mean_variance_axis0\n from ..utils.sparsefuncs import count_nonzero\n@@ -100,6 +101,7 @@ class IsolationForest(BaseEnsemble, OutlierMixin):\n     n_estimators = None\n     contamination = 'auto'\n     max_samples = 'auto'\n+    warm_start = False\n \n     def __init__(self, n_estimators=100, max_samples='auto', contamination='auto',\n                  max_features=1., bootstrap=False, n_jobs=None,\n@@ -110,6 +112,7 @@ class IsolationForest(BaseEnsemble, OutlierMixin):\n         self.n_estimators = n_estimators\n         self.max_samples = max_samples\n         self.contamination = contamination\n+        self.warm_start = warm_start\n         self.max_features = max_features\n         self.bootstrap = bootstrap\n         self.n_jobs = n_jobs\n@@ -120,6 +123,7 @@ class IsolationForest(BaseEnsemble, OutlierMixin):\n \n     def _fit(self, X, y=None):\n         # Check data\n+        check_is_fitted(self)\n         X = check_array(X, accept_sparse=\"csr\", dtype=DTYPE)\n         if isinstance(self.max_samples, str) and self.max_samples == 'auto':\n             self.max_samples = min(256, X.shape[0])\n@@ -130,6 +134,7 @@ class IsolationForest(BaseEnsemble, OutlierMixin):\n                 raise ValueError(\"max_samples must be in range (0, n_samples], \"\n                                  \" got %r\" % self.max_samples)\n \n+        if self.warm_start and hasattr(self, 'estimators_'):\n+            n_estimators_to_add = self.n_estimators - len(self.estimators_)\n+            self.n_estimators = len(self.estimators_)\n+            self._fit_stage(X, n_estimators_to_add)\n+        else:\n             self.estimators_ = []\n             self.estimators_features_ = []\n             self.estimators_samples_ = []\n@@ -140,6 +147,7 @@ class IsolationForest(BaseEnsemble, OutlierMixin):\n             self.estimators_n_node_samples_ = np.zeros((self.n_estimators,), dtype=np.int32)\n             self.estimators_max_depth_ = np.zeros((self.n_estimators,), dtype=np.int32)\n \n+            self._fit_stage(X, self.n_estimators)\n+\n         return self\n \n     def _fit_stage(self, X, n_estimators):\ndiff --git a/sklearn/ensemble/tests/test_iforest.py b/sklearn/ensemble/tests/test_iforest.py\nindex 5a6b7c8..9d0e1f2 100644\n--- a/sklearn/ensemble/tests/test_iforest.py\n+++ b/sklearn/ensemble/tests/test_iforest.py\n@@ -10,6 +10,7 @@\n from sklearn.datasets import make_classification\n from sklearn.metrics import roc_auc_score\n from sklearn.utils.testing import assert_almost_equal, assert_raises, assert_true\n+from sklearn.utils.testing import assert_array_equal\n from sklearn.utils.validation import NotFittedError\n \n \n@@ -100,6 +101,14 @@ def test_iforest():\n     assert_almost_equal(auc, 0.9, decimal=2)\n \n \n+def test_warm_start():\n+    X, y = make_classification(n_samples=100, n_features=20, random_state=42)\n+    clf = IsolationForest(warm_start=True, n_estimators=50)\n+    clf.fit(X)\n+    clf.set_params(n_estimators=100)\n+    clf.fit(X)\n+    assert_array_equal(len(clf.estimators_), 100)\n+\n \n if __name__ == '__main__':\n     import nose",
    "patch_lines_added": 0,
    "patch_lines_removed": 0,
    "files_changed": 0,
    "timestamp": "2026-02-13T01:15:24.809357",
    "seed": 42,
    "repo": "scikit-learn/scikit-learn",
    "base_commit": "3aefc834dce72e850bff48689bea3c7dff5f3fad",
    "taxonomy_version": "B-v2-step2-C",
    "gen_elapsed_sec": 11.204965114593506,
    "context_used": true,
    "context_num_files": 80,
    "repo_context_preview": "Existing files (choose from these):\nsetup.py\nconftest.py\ndoc/conf.py\ndoc/conftest.py\nsklearn/base.py\nsklearn/dummy.py\nsklearn/setup.py\nsklearn/impute.py\nsklearn/_config.py\nsklearn/__init__.py\nsklearn/isotonic.py\nsklearn/pipeline.py\nsklearn/svm/base.py\nsklearn/svm/setup.py\nsklearn/tree/tree.py\nsklearn/exceptions.py\nsklearn/multiclass.py\nsklearn/svm/bounds.py\nsklearn/tree/setup.py\nsklearn/calibration.py\n... (+60 more)",
    "stdout": "",
    "stderr": "",
    "returncode": null,
    "timeout": false,
    "elapsed_sec": 11.204965114593506,
    "signature": "invalid_diff_format",
    "test_command": "",
    "stage": "GEN",
    "error_type": "GEN_FAIL",
    "success": false
  }
}