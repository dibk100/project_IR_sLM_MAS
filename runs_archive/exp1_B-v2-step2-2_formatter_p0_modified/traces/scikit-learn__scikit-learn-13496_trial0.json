{
  "task_id": "scikit-learn__scikit-learn-13496",
  "trial_id": 0,
  "context_used": true,
  "context_num_files": 80,
  "repo_context_preview": "Existing files (choose from these):\nsetup.py\nconftest.py\ndoc/conf.py\ndoc/conftest.py\nsklearn/base.py\nsklearn/dummy.py\nsklearn/setup.py\nsklearn/impute.py\nsklearn/_config.py\nsklearn/__init__.py\nsklearn/isotonic.py\nsklearn/pipeline.py\nsklearn/svm/base.py\nsklearn/svm/setup.py\nsklearn/tree/tree.py\nsklearn/exceptions.py\nsklearn/multiclass.py\nsklearn/svm/bounds.py\nsklearn/tree/setup.py\nsklearn/calibration.py\n... (+60 more)",
  "format_used": true,
  "format_ok": false,
  "format_reason": "too_many_files(3)",
  "issue_text": null,
  "test_command": "",
  "diff": "diff --git a/sklearn/ensemble/base.py b/sklearn/ensemble/base.py\nindex 9b8c2d3..e4f5a6b 100644\n--- a/sklearn/ensemble/base.py\n+++ b/sklearn/ensemble/base.py\n@@ -100,6 +100,7 @@ class BaseBagging(MetaEstimatorMixin, ClassifierMixin, RegressorMixin,\n     n_estimators = None\n     max_samples = 1.0\n     max_features = 1.0\n+    warm_start = False\n \n     def __init__(self, base_estimator=None, n_estimators=100, max_samples=1.0,\n                  max_features=1.0, bootstrap=True, bootstrap_features=False,\ndiff --git a/sklearn/ensemble/iforest.py b/sklearn/ensemble/iforest.py\nindex 1a2b3c4..5d6e7f8 100644\n--- a/sklearn/ensemble/iforest.py\n+++ b/sklearn/ensemble/iforest.py\n@@ -10,6 +10,7 @@\n from ..base import BaseEnsemble, OutlierMixin\n from ..tree._tree import DTYPE, DOUBLE\n from ..utils.validation import check_X_y, check_array\n+from ..utils.validation import check_is_fitted\n from ..utils.extmath import weighted_mode\n from ..utils.fixes import _object_dtype_isnan\n \n@@ -100,6 +101,7 @@ class IsolationForest(BaseEnsemble, OutlierMixin):\n     n_estimators = None\n     contamination = 'auto'\n     max_samples = 1.0\n+    warm_start = False\n \n     def __init__(self, n_estimators=100, max_samples='auto', contamination='auto',\n                  max_features=1., bootstrap=False, n_jobs=None,\n@@ -110,6 +112,7 @@ class IsolationForest(BaseEnsemble, OutlierMixin):\n         self.max_samples = max_samples\n         self.contamination = contamination\n         self.max_features = max_features\n+        self.warm_start = warm_start\n \n     def fit(self, X, y=None):\n         \"\"\"Fit estimator.\n@@ -120,6 +123,10 @@ class IsolationForest(BaseEnsemble, OutlierMixin):\n             raise ValueError(\"max_samples must be in range (0, n_samples], \"\n                              \" got %r\" % self.max_samples)\n \n+        if self.warm_start and hasattr(self, 'estimators_'):\n+            n_estimators_old = len(self.estimators_)\n+            self.n_estimators += n_estimators_old\n+\n         # Check parameters\n         X = check_array(X, accept_sparse=\"csr\", dtype=DTYPE)\n         if isinstance(self.max_samples, str) and self.max_samples == 'auto':\n@@ -130,6 +137,10 @@ class IsolationForest(BaseEnsemble, OutlierMixin):\n                 self.max_samples = int(n_samples * self.max_samples)\n             else:\n                 raise ValueError('max_samples should be in (0, n_samples] '\n-                                 'for string value')\n+                                 'for string value, got %r' % self.max_samples)\n+\n+        if self.warm_start and hasattr(self, 'estimators_'):\n+            self.estimators_ += self._fit(X, y, sample_weight)\n+        else:\n+            self.estimators_ = self._fit(X, y, sample_weight)\n \n         return self\n \ndiff --git a/sklearn/ensemble/tests/test_iforest.py b/sklearn/ensemble/tests/test_iforest.py\nindex 9a8b7c6..d5e4f32 100644\n--- a/sklearn/ensemble/tests/test_iforest.py\n+++ b/sklearn/ensemble/tests/test_iforest.py\n@@ -10,6 +10,7 @@\n from sklearn.datasets import make_classification\n from sklearn.metrics import roc_auc_score\n from sklearn.utils.testing import assert_almost_equal, assert_raises\n+from sklearn.utils.testing import assert_true\n \n \n def test_iforest():\n@@ -20,6 +21,10 @@ def test_iforest():\n     X_train, y_train = make_classification(n_samples=100, n_features=20,\n                                            random_state=42)\n     clf = IsolationForest(random_state=42).fit(X_train)\n+    assert_true(hasattr(clf, 'warm_start'))\n+    assert_false(clf.warm_start)\n+    clf.warm_start = True\n+    clf.fit(X_train)\n     scores = clf.decision_function(X_train)\n     assert_almost_equal(roc_auc_score(y_train, scores), 0.9, decimal=2)",
  "stdout": "",
  "stderr": "",
  "repo_commit": null,
  "docker_image": null,
  "model_config": null,
  "full_result": {
    "task_id": "scikit-learn__scikit-learn-13496",
    "trial_id": 0,
    "model": "Qwen/Qwen2.5-Coder-7B-Instruct",
    "prompt_hash": "6f0b73256c1d49e5e01b29127db1bd2a4332f4da700c0ffecaecd78434a64219",
    "diff": "diff --git a/sklearn/ensemble/base.py b/sklearn/ensemble/base.py\nindex 9b8c2d3..e4f5a6b 100644\n--- a/sklearn/ensemble/base.py\n+++ b/sklearn/ensemble/base.py\n@@ -100,6 +100,7 @@ class BaseBagging(MetaEstimatorMixin, ClassifierMixin, RegressorMixin,\n     n_estimators = None\n     max_samples = 1.0\n     max_features = 1.0\n+    warm_start = False\n \n     def __init__(self, base_estimator=None, n_estimators=100, max_samples=1.0,\n                  max_features=1.0, bootstrap=True, bootstrap_features=False,\ndiff --git a/sklearn/ensemble/iforest.py b/sklearn/ensemble/iforest.py\nindex 1a2b3c4..5d6e7f8 100644\n--- a/sklearn/ensemble/iforest.py\n+++ b/sklearn/ensemble/iforest.py\n@@ -10,6 +10,7 @@\n from ..base import BaseEnsemble, OutlierMixin\n from ..tree._tree import DTYPE, DOUBLE\n from ..utils.validation import check_X_y, check_array\n+from ..utils.validation import check_is_fitted\n from ..utils.extmath import weighted_mode\n from ..utils.fixes import _object_dtype_isnan\n \n@@ -100,6 +101,7 @@ class IsolationForest(BaseEnsemble, OutlierMixin):\n     n_estimators = None\n     contamination = 'auto'\n     max_samples = 1.0\n+    warm_start = False\n \n     def __init__(self, n_estimators=100, max_samples='auto', contamination='auto',\n                  max_features=1., bootstrap=False, n_jobs=None,\n@@ -110,6 +112,7 @@ class IsolationForest(BaseEnsemble, OutlierMixin):\n         self.max_samples = max_samples\n         self.contamination = contamination\n         self.max_features = max_features\n+        self.warm_start = warm_start\n \n     def fit(self, X, y=None):\n         \"\"\"Fit estimator.\n@@ -120,6 +123,10 @@ class IsolationForest(BaseEnsemble, OutlierMixin):\n             raise ValueError(\"max_samples must be in range (0, n_samples], \"\n                              \" got %r\" % self.max_samples)\n \n+        if self.warm_start and hasattr(self, 'estimators_'):\n+            n_estimators_old = len(self.estimators_)\n+            self.n_estimators += n_estimators_old\n+\n         # Check parameters\n         X = check_array(X, accept_sparse=\"csr\", dtype=DTYPE)\n         if isinstance(self.max_samples, str) and self.max_samples == 'auto':\n@@ -130,6 +137,10 @@ class IsolationForest(BaseEnsemble, OutlierMixin):\n                 self.max_samples = int(n_samples * self.max_samples)\n             else:\n                 raise ValueError('max_samples should be in (0, n_samples] '\n-                                 'for string value')\n+                                 'for string value, got %r' % self.max_samples)\n+\n+        if self.warm_start and hasattr(self, 'estimators_'):\n+            self.estimators_ += self._fit(X, y, sample_weight)\n+        else:\n+            self.estimators_ = self._fit(X, y, sample_weight)\n \n         return self\n \ndiff --git a/sklearn/ensemble/tests/test_iforest.py b/sklearn/ensemble/tests/test_iforest.py\nindex 9a8b7c6..d5e4f32 100644\n--- a/sklearn/ensemble/tests/test_iforest.py\n+++ b/sklearn/ensemble/tests/test_iforest.py\n@@ -10,6 +10,7 @@\n from sklearn.datasets import make_classification\n from sklearn.metrics import roc_auc_score\n from sklearn.utils.testing import assert_almost_equal, assert_raises\n+from sklearn.utils.testing import assert_true\n \n \n def test_iforest():\n@@ -20,6 +21,10 @@ def test_iforest():\n     X_train, y_train = make_classification(n_samples=100, n_features=20,\n                                            random_state=42)\n     clf = IsolationForest(random_state=42).fit(X_train)\n+    assert_true(hasattr(clf, 'warm_start'))\n+    assert_false(clf.warm_start)\n+    clf.warm_start = True\n+    clf.fit(X_train)\n     scores = clf.decision_function(X_train)\n     assert_almost_equal(roc_auc_score(y_train, scores), 0.9, decimal=2)",
    "patch_lines_added": 0,
    "patch_lines_removed": 0,
    "files_changed": 0,
    "timestamp": "2026-02-17T10:10:37.383633",
    "seed": 42,
    "repo": "scikit-learn/scikit-learn",
    "base_commit": "3aefc834dce72e850bff48689bea3c7dff5f3fad",
    "taxonomy_version": "B-v2-step2-2",
    "gen_elapsed_sec": 10.28867483139038,
    "context_used": true,
    "context_num_files": 80,
    "repo_context_preview": "Existing files (choose from these):\nsetup.py\nconftest.py\ndoc/conf.py\ndoc/conftest.py\nsklearn/base.py\nsklearn/dummy.py\nsklearn/setup.py\nsklearn/impute.py\nsklearn/_config.py\nsklearn/__init__.py\nsklearn/isotonic.py\nsklearn/pipeline.py\nsklearn/svm/base.py\nsklearn/svm/setup.py\nsklearn/tree/tree.py\nsklearn/exceptions.py\nsklearn/multiclass.py\nsklearn/svm/bounds.py\nsklearn/tree/setup.py\nsklearn/calibration.py\n... (+60 more)",
    "format_used": true,
    "format_ok": false,
    "format_reason": "too_many_files(3)",
    "stdout": "",
    "stderr": "",
    "returncode": null,
    "timeout": false,
    "elapsed_sec": 10.28867483139038,
    "signature": "invalid_diff_format",
    "test_command": "",
    "stage": "GEN",
    "error_type": "GEN_FAIL",
    "success": false
  }
}