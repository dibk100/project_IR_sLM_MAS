{
  "task_id": "pydata__xarray-3364",
  "trial_id": 0,
  "issue_text": null,
  "test_command": "git apply",
  "diff": "diff --git a/xarray/core/concat.py b/xarray/core/concat.py\nindex 1a2b3c4..5d6e7f8 100644\n--- a/xarray/core/concat.py\n+++ b/xarray/core/concat.py\n@@ -10,6 +10,7 @@\n import numpy as np\n import pandas as pd\n \n+from .common import merge_coordinates\n from .dataarray import DataArray\n from .dataset import Dataset\n from .utils import _maybe_wrap_array, _maybe_wrap_dataset, _safe_cast_to_index\n@@ -100,6 +101,10 @@ def concat(objs, dim=None, coords='different', compat='broadcast_equals',\n     \"\"\"\n     Concatenate a sequence of objects along a particular dimension.\n \n+    Parameters\n+    ----------\n+    objs : sequence of Dataset or DataArray objects\n+        The objects to concatenate.\n     dim : str, optional\n         Dimension along which to concatenate. If None, concatenation is attempted\n         over all dimensions.\n@@ -110,6 +115,10 @@ def concat(objs, dim=None, coords='different', compat='broadcast_equals',\n     compat : {'broadcast_equals', 'identical'}, optional\n         How to compare objects for compatibility. See `Dataset.equals`.\n \n+    Returns\n+    -------\n+    concatenated : Dataset or DataArray\n+        The concatenated object.\n     \"\"\"\n     if dim is None:\n         dims = set()\n@@ -120,6 +129,10 @@ def concat(objs, dim=None, coords='different', compat='broadcast_equals',\n             dims.add(key)\n         dim = sorted(dims)[0]\n \n+    # Merge coordinates to handle missing variables\n+    merged_coords = merge_coordinates([obj.coords for obj in objs], method=coords)\n+\n     if isinstance(objs[0], Dataset):\n         return _concat_datasets(objs, dim, coords, compat)\n     elif isinstance(objs[0], DataArray):\n@@ -130,6 +143,10 @@ def concat(objs, dim=None, coords='different', compat='broadcast_equals',\n         raise TypeError(\"All objects must be either Dataset or DataArray\")\n \n \n+def merge_coordinates(coords_list, method='different'):\n+    \"\"\"Merge coordinates from multiple datasets or dataarrays.\"\"\"\n+    return {key: merge_coordinate_values(coord_dict[key] for coord_dict in coords_list, method=method) for key in set().union(*coord_dict.keys())}\n+\n+\n def merge_coordinate_values(values, method='different'):\n     \"\"\"Merge coordinate values based on the specified method.\"\"\"\n     if method == 'different':\n@@ -140,6 +157,10 @@ def merge_coordinate_values(values, method='different'):\n         return pd.concat(values, axis=0, ignore_index=True)\n     else:\n         raise ValueError(f\"Invalid method: {method}\")\n+\n+\n+def _concat_datasets(objs, dim, coords, compat):\n+    \"\"\"Concatenate datasets along a specific dimension.\"\"\"\n     # Check compatibility\n     if compat == 'broadcast_equals':\n         for i, obj in enumerate(objs):\n@@ -150,6 +171,10 @@ def _concat_datasets(objs, dim, coords, compat):\n                 raise ValueError(f\"Incompatible objects at index {i}: {err}\")\n \n     # Concatenate\n+    merged_coords = merge_coordinates([obj.coords for obj in objs], method=coords)\n     result = xr.Dataset()\n     for var_name, var in objs[0].items():\n         if var_name in result:\n@@ -160,6 +185,10 @@ def _concat_datasets(objs, dim, coords, compat):\n                 result[var_name] = xr.concat([var, var_new], dim=dim)\n             else:\n                 result[var_name] = var_new\n+\n+    # Assign merged coordinates to the result\n+    result.coords.update(merged_coords)\n+\n     return result",
  "stdout": "",
  "stderr": "Git Apply Failed: error: corrupt patch at line 45\n",
  "repo_commit": null,
  "docker_image": "swebench/sweb.eval.x86_64:latest",
  "model_config": null,
  "full_result": {
    "task_id": "pydata__xarray-3364",
    "trial_id": 0,
    "model": "Qwen/Qwen2.5-Coder-7B-Instruct",
    "prompt_hash": "c3faaa494457a49a95f04d09f0e4c0fe9b9ce0353e6ac55bb37dbd0cfe4c8317",
    "diff": "diff --git a/xarray/core/concat.py b/xarray/core/concat.py\nindex 1a2b3c4..5d6e7f8 100644\n--- a/xarray/core/concat.py\n+++ b/xarray/core/concat.py\n@@ -10,6 +10,7 @@\n import numpy as np\n import pandas as pd\n \n+from .common import merge_coordinates\n from .dataarray import DataArray\n from .dataset import Dataset\n from .utils import _maybe_wrap_array, _maybe_wrap_dataset, _safe_cast_to_index\n@@ -100,6 +101,10 @@ def concat(objs, dim=None, coords='different', compat='broadcast_equals',\n     \"\"\"\n     Concatenate a sequence of objects along a particular dimension.\n \n+    Parameters\n+    ----------\n+    objs : sequence of Dataset or DataArray objects\n+        The objects to concatenate.\n     dim : str, optional\n         Dimension along which to concatenate. If None, concatenation is attempted\n         over all dimensions.\n@@ -110,6 +115,10 @@ def concat(objs, dim=None, coords='different', compat='broadcast_equals',\n     compat : {'broadcast_equals', 'identical'}, optional\n         How to compare objects for compatibility. See `Dataset.equals`.\n \n+    Returns\n+    -------\n+    concatenated : Dataset or DataArray\n+        The concatenated object.\n     \"\"\"\n     if dim is None:\n         dims = set()\n@@ -120,6 +129,10 @@ def concat(objs, dim=None, coords='different', compat='broadcast_equals',\n             dims.add(key)\n         dim = sorted(dims)[0]\n \n+    # Merge coordinates to handle missing variables\n+    merged_coords = merge_coordinates([obj.coords for obj in objs], method=coords)\n+\n     if isinstance(objs[0], Dataset):\n         return _concat_datasets(objs, dim, coords, compat)\n     elif isinstance(objs[0], DataArray):\n@@ -130,6 +143,10 @@ def concat(objs, dim=None, coords='different', compat='broadcast_equals',\n         raise TypeError(\"All objects must be either Dataset or DataArray\")\n \n \n+def merge_coordinates(coords_list, method='different'):\n+    \"\"\"Merge coordinates from multiple datasets or dataarrays.\"\"\"\n+    return {key: merge_coordinate_values(coord_dict[key] for coord_dict in coords_list, method=method) for key in set().union(*coord_dict.keys())}\n+\n+\n def merge_coordinate_values(values, method='different'):\n     \"\"\"Merge coordinate values based on the specified method.\"\"\"\n     if method == 'different':\n@@ -140,6 +157,10 @@ def merge_coordinate_values(values, method='different'):\n         return pd.concat(values, axis=0, ignore_index=True)\n     else:\n         raise ValueError(f\"Invalid method: {method}\")\n+\n+\n+def _concat_datasets(objs, dim, coords, compat):\n+    \"\"\"Concatenate datasets along a specific dimension.\"\"\"\n     # Check compatibility\n     if compat == 'broadcast_equals':\n         for i, obj in enumerate(objs):\n@@ -150,6 +171,10 @@ def _concat_datasets(objs, dim, coords, compat):\n                 raise ValueError(f\"Incompatible objects at index {i}: {err}\")\n \n     # Concatenate\n+    merged_coords = merge_coordinates([obj.coords for obj in objs], method=coords)\n     result = xr.Dataset()\n     for var_name, var in objs[0].items():\n         if var_name in result:\n@@ -160,6 +185,10 @@ def _concat_datasets(objs, dim, coords, compat):\n                 result[var_name] = xr.concat([var, var_new], dim=dim)\n             else:\n                 result[var_name] = var_new\n+\n+    # Assign merged coordinates to the result\n+    result.coords.update(merged_coords)\n+\n     return result",
    "patch_lines_added": 26,
    "patch_lines_removed": 0,
    "files_changed": 1,
    "timestamp": "2026-02-12T20:21:58.389854",
    "seed": 42,
    "repo": "pydata/xarray",
    "base_commit": "863e49066ca4d61c9adfe62aca3bf21b90e1af8c",
    "taxonomy_version": "B-v2-step2-A",
    "gen_elapsed_sec": 8.514190196990967,
    "stage": "PATCH",
    "stdout": "",
    "stderr": "Git Apply Failed: error: corrupt patch at line 45\n",
    "returncode": 128,
    "timeout": false,
    "elapsed_sec": 0.47138166427612305,
    "test_command": "git apply",
    "success": false,
    "error_type": "PATCH_FAIL",
    "signature": "git_apply_corrupt_patch",
    "docker_image": "swebench/sweb.eval.x86_64:latest"
  }
}