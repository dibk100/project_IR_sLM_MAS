{
  "task_id": "scikit-learn__scikit-learn-13496",
  "trial_id": 0,
  "context_used": true,
  "context_num_files": 80,
  "repo_context_preview": "Existing files (choose from these):\nsetup.py\nconftest.py\ndoc/conf.py\ndoc/conftest.py\nsklearn/base.py\nsklearn/dummy.py\nsklearn/setup.py\nsklearn/_config.py\nsklearn/__init__.py\nsklearn/conftest.py\nsklearn/isotonic.py\nsklearn/pipeline.py\nsklearn/svm/base.py\nsklearn/svm/setup.py\nsklearn/tree/tree.py\nsklearn/exceptions.py\nsklearn/multiclass.py\nsklearn/svm/bounds.py\nsklearn/tree/setup.py\nsklearn/calibration.py\n... (+60 more)",
  "format_used": true,
  "format_ok": false,
  "format_reason": "formatter_invalid:too_many_files(3)",
  "issue_text": null,
  "test_command": "",
  "diff": "diff --git a/sklearn/ensemble/base.py b/sklearn/ensemble/base.py\nindex 9b8c2d3..e4f5a6b 100644\n--- a/sklearn/ensemble/base.py\n+++ b/sklearn/ensemble/base.py\n@@ -100,6 +100,7 @@ class BaseBagging(MetaEstimatorMixin, ClassifierMixin, RegressorMixin,\n     n_jobs=None,\n     random_state=None,\n     verbose=0,\n+    warm_start=False,\n ):\n     \"\"\"Base class for Bagging meta-estimator.\"\"\"\n \n@@ -110,6 +111,7 @@ class BaseBagging(MetaEstimatorMixin, ClassifierMixin, RegressorMixin,\n         self.n_jobs = n_jobs\n         self.random_state = random_state\n         self.verbose = verbose\n+        self.warm_start = warm_start\n \n     def _validate_estimator(self, estimator):\n         \"\"\"Check estimator and set base_estimator_ attribute.\"\"\"\ndiff --git a/sklearn/ensemble/iforest.py b/sklearn/ensemble/iforest.py\nindex 1a2b3c4..5d6e7f8 100644\n--- a/sklearn/ensemble/iforest.py\n+++ b/sklearn/ensemble/iforest.py\n@@ -10,6 +10,7 @@\n from ..tree import DecisionTreeClassifier\n from ..utils.validation import check_X_y\n from ..utils.validation import check_array\n+from .base import BaseBagging\n \n __all__ = [\"IsolationForest\"]\n \n@@ -20,7 +21,7 @@ class IsolationForest(BaseAnomalyDetector):\n     \"\"\"\n     An Isolation Forest for anomaly detection based on tree ensembles.\n \n-    Parameters\n+    Parameters (inherited from BaseBagging)\n     ----------\n     n_estimators : int, optional (default=100)\n         The number of trees in the forest.\n@@ -30,6 +31,11 @@ class IsolationForest(BaseAnomalyDetector):\n         The maximum depth of the trees. If None, then nodes are expanded until\n         all leaves are pure or until all leaves contain less than min_samples_split\n         samples.\n+\n+    warm_start : bool, optional (default=False)\n+        When set to ``True``, reuse the solution of the previous call to fit\n+        and add more estimators to the ensemble, otherwise, just fit a whole\n+        new forest. See :term:`the Glossary <warm_start>`.\n     \"\"\"\n \n     def __init__(self,\n@@ -40,6 +46,7 @@ class IsolationForest(BaseAnomalyDetector):\n                 max_depth=None,\n                 contamination='auto',\n                 random_state=None,\n+                warm_start=False,\n                 verbose=0):\n         super().__init__(\n             base_estimator=DecisionTreeClassifier(max_features=1),\n@@ -47,6 +54,7 @@ class IsolationForest(BaseAnomalyDetector):\n             n_estimators=n_estimators,\n             max_depth=max_depth,\n             contamination=contamination,\n+            warm_start=warm_start,\n             random_state=random_state,\n             verbose=verbose)\n \ndiff --git a/sklearn/ensemble/test_base.py b/sklearn/ensemble/test_base.py\nindex 9a8b7c6..8d7e6f5 100644\n--- a/sklearn/ensemble/test_base.py\n+++ b/sklearn/ensemble/test_base.py\n@@ -10,6 +10,7 @@\n from sklearn.datasets import make_classification\n from sklearn.utils.testing import assert_raises\n from sklearn.utils.testing import assert_array_almost_equal\n+from sklearn.ensemble.base import BaseBagging\n \n __all__ = [\n     \"test_base_bagging\",\n@@ -20,6 +21,11 @@ def test_base_bagging():\n     X, y = make_classification(n_samples=100, n_features=20, random_state=42)\n     clf = BaseBagging(base_estimator=None, n_estimators=10, random_state=42)\n     clf.fit(X, y)\n+    clf.set_params(warm_start=True)\n+    clf.fit(X, y)\n+    assert len(clf.estimators_) == 20\n+    clf.set_params(warm_start=False)\n+    clf.fit(X, y)\n+    assert len(clf.estimators_) == 10",
  "stdout": "",
  "stderr": "",
  "repo_commit": null,
  "docker_image": null,
  "model_config": null,
  "full_result": {
    "task_id": "scikit-learn__scikit-learn-13496",
    "trial_id": 0,
    "model": "Qwen/Qwen2.5-Coder-7B-Instruct",
    "prompt_hash": "6f0b73256c1d49e5e01b29127db1bd2a4332f4da700c0ffecaecd78434a64219",
    "diff": "diff --git a/sklearn/ensemble/base.py b/sklearn/ensemble/base.py\nindex 9b8c2d3..e4f5a6b 100644\n--- a/sklearn/ensemble/base.py\n+++ b/sklearn/ensemble/base.py\n@@ -100,6 +100,7 @@ class BaseBagging(MetaEstimatorMixin, ClassifierMixin, RegressorMixin,\n     n_jobs=None,\n     random_state=None,\n     verbose=0,\n+    warm_start=False,\n ):\n     \"\"\"Base class for Bagging meta-estimator.\"\"\"\n \n@@ -110,6 +111,7 @@ class BaseBagging(MetaEstimatorMixin, ClassifierMixin, RegressorMixin,\n         self.n_jobs = n_jobs\n         self.random_state = random_state\n         self.verbose = verbose\n+        self.warm_start = warm_start\n \n     def _validate_estimator(self, estimator):\n         \"\"\"Check estimator and set base_estimator_ attribute.\"\"\"\ndiff --git a/sklearn/ensemble/iforest.py b/sklearn/ensemble/iforest.py\nindex 1a2b3c4..5d6e7f8 100644\n--- a/sklearn/ensemble/iforest.py\n+++ b/sklearn/ensemble/iforest.py\n@@ -10,6 +10,7 @@\n from ..tree import DecisionTreeClassifier\n from ..utils.validation import check_X_y\n from ..utils.validation import check_array\n+from .base import BaseBagging\n \n __all__ = [\"IsolationForest\"]\n \n@@ -20,7 +21,7 @@ class IsolationForest(BaseAnomalyDetector):\n     \"\"\"\n     An Isolation Forest for anomaly detection based on tree ensembles.\n \n-    Parameters\n+    Parameters (inherited from BaseBagging)\n     ----------\n     n_estimators : int, optional (default=100)\n         The number of trees in the forest.\n@@ -30,6 +31,11 @@ class IsolationForest(BaseAnomalyDetector):\n         The maximum depth of the trees. If None, then nodes are expanded until\n         all leaves are pure or until all leaves contain less than min_samples_split\n         samples.\n+\n+    warm_start : bool, optional (default=False)\n+        When set to ``True``, reuse the solution of the previous call to fit\n+        and add more estimators to the ensemble, otherwise, just fit a whole\n+        new forest. See :term:`the Glossary <warm_start>`.\n     \"\"\"\n \n     def __init__(self,\n@@ -40,6 +46,7 @@ class IsolationForest(BaseAnomalyDetector):\n                 max_depth=None,\n                 contamination='auto',\n                 random_state=None,\n+                warm_start=False,\n                 verbose=0):\n         super().__init__(\n             base_estimator=DecisionTreeClassifier(max_features=1),\n@@ -47,6 +54,7 @@ class IsolationForest(BaseAnomalyDetector):\n             n_estimators=n_estimators,\n             max_depth=max_depth,\n             contamination=contamination,\n+            warm_start=warm_start,\n             random_state=random_state,\n             verbose=verbose)\n \ndiff --git a/sklearn/ensemble/test_base.py b/sklearn/ensemble/test_base.py\nindex 9a8b7c6..8d7e6f5 100644\n--- a/sklearn/ensemble/test_base.py\n+++ b/sklearn/ensemble/test_base.py\n@@ -10,6 +10,7 @@\n from sklearn.datasets import make_classification\n from sklearn.utils.testing import assert_raises\n from sklearn.utils.testing import assert_array_almost_equal\n+from sklearn.ensemble.base import BaseBagging\n \n __all__ = [\n     \"test_base_bagging\",\n@@ -20,6 +21,11 @@ def test_base_bagging():\n     X, y = make_classification(n_samples=100, n_features=20, random_state=42)\n     clf = BaseBagging(base_estimator=None, n_estimators=10, random_state=42)\n     clf.fit(X, y)\n+    clf.set_params(warm_start=True)\n+    clf.fit(X, y)\n+    assert len(clf.estimators_) == 20\n+    clf.set_params(warm_start=False)\n+    clf.fit(X, y)\n+    assert len(clf.estimators_) == 10",
    "patch_lines_added": 0,
    "patch_lines_removed": 0,
    "files_changed": 0,
    "timestamp": "2026-02-17T13:36:11.565790",
    "seed": 42,
    "repo": "scikit-learn/scikit-learn",
    "base_commit": "3aefc834dce72e850bff48689bea3c7dff5f3fad",
    "taxonomy_version": "B-v2-step2-2",
    "gen_elapsed_sec": 9.527489185333252,
    "context_used": true,
    "context_num_files": 80,
    "repo_context_preview": "Existing files (choose from these):\nsetup.py\nconftest.py\ndoc/conf.py\ndoc/conftest.py\nsklearn/base.py\nsklearn/dummy.py\nsklearn/setup.py\nsklearn/_config.py\nsklearn/__init__.py\nsklearn/conftest.py\nsklearn/isotonic.py\nsklearn/pipeline.py\nsklearn/svm/base.py\nsklearn/svm/setup.py\nsklearn/tree/tree.py\nsklearn/exceptions.py\nsklearn/multiclass.py\nsklearn/svm/bounds.py\nsklearn/tree/setup.py\nsklearn/calibration.py\n... (+60 more)",
    "format_used": true,
    "format_ok": false,
    "format_reason": "formatter_invalid:too_many_files(3)",
    "apply_check_ok": false,
    "apply_check_reason": "",
    "stdout": "",
    "stderr": "",
    "returncode": null,
    "timeout": false,
    "elapsed_sec": 9.527489185333252,
    "signature": "invalid_diff_format",
    "test_command": "",
    "stage": "GEN",
    "error_type": "GEN_FAIL",
    "success": false
  }
}